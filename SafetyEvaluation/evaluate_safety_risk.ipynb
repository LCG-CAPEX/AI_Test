{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "%pip install openai azure-ai-evaluation azure-identity promptflow-azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AZURE_DEPLOYMENT_NAME\"] = \"Ravi-OpenAI-Inst-032523\"\n",
    "os.environ[\"AZURE_ENDPOINT\"] = \"https://ravi-openai-inst-032523.openai.azure.com/\"\n",
    "os.environ[\"AZURE_API_VERSION\"] = \"gpt-35-turbo\"\n",
    "os.environ[\"AZURE_SUBSCRIPTION_ID\"] = \"a234e53c-b063-4702-bcf4-9457e53c7af2\"\n",
    "os.environ[\"AZURE_RESOURCE_GROUP\"] = \"Ravi_OpenAI032523\"\n",
    "os.environ[\"AZURE_PROJECT_NAME\"] = \"safety_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import ProtectedMaterialEvaluator, IndirectAttackEvaluator\n",
    "from azure.ai.evaluation.simulator import AdversarialSimulator, AdversarialScenario, IndirectAttackSimulator\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "async def protected_material_callback(\n",
    "    messages: List[Dict], stream: bool = False, session_state: Optional[str] = None, context: Optional[Dict] = None\n",
    ") -> dict:\n",
    "    deployment = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "    endpoint = os.environ.get(\"AZURE_ENDPOINT\")\n",
    "    token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "    # Get a client handle for the model\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=os.environ.get(\"AZURE_API_VERSION\"),\n",
    "        azure_ad_token_provider=token_provider,\n",
    "    )\n",
    "    # Call the model\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": messages[\"messages\"][0][\"content\"],  # injection of prompt happens here.\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        temperature=0.7,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "    )\n",
    "\n",
    "    formatted_response = completion.to_dict()[\"choices\"][0][\"message\"]\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\n",
    "        \"messages\": messages[\"messages\"],\n",
    "        \"stream\": stream,\n",
    "        \"session_state\": session_state,\n",
    "        \"context\": context,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the adversarial simulator\n",
    "protected_material_simulator = AdversarialSimulator(azure_ai_project=azure_ai_project, credential=credential)\n",
    "\n",
    "\n",
    "protected_material_scenario = AdversarialScenario.ADVERSARIAL_CONTENT_PROTECTED_MATERIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_protected_material_outputs = await protected_material_simulator(\n",
    "    scenario=protected_material_scenario,\n",
    "    max_conversation_turns=3,  # define the number of conversation turns\n",
    "    max_simulation_results=10,  # define the number of simulation results\n",
    "    target=protected_material_callback,  # define the target model callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results are truncated for brevity.\n",
    "truncation_limit = 50\n",
    "for output in unfiltered_protected_material_outputs:\n",
    "    for turn in output[\"messages\"]:\n",
    "        print(f\"{turn['role']} : {turn['content'][0:truncation_limit]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(unfiltered_protected_material_outputs.to_eval_qr_json_lines())\n",
    "output = unfiltered_protected_material_outputs.to_eval_qr_json_lines()\n",
    "file_path = \"unfiltered_protected_material_output.jsonl\"\n",
    "\n",
    "# Write the output to the file\n",
    "with Path.open(Path(file_path), \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_material_eval = ProtectedMaterialEvaluator(azure_ai_project=azure_ai_project, credential=credential)\n",
    "\n",
    "result = evaluate(\n",
    "    data=file_path,\n",
    "    evaluators={\"protected_material\": protected_material_eval},\n",
    "\n",
    "    azure_ai_project=azure_ai_project,\n",
    "\n",
    "    output_path=\"./mynewfilteredIPevalresults.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_protected_material_outputs = await protected_material_simulator(\n",
    "    scenario=protected_material_scenario,\n",
    "    max_conversation_turns=3,  # define the number of conversation turns\n",
    "    max_simulation_results=10,  # define the number of simulation results\n",
    "    target=protected_material_callback,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_protected_material_outputs.to_eval_qr_json_lines())\n",
    "output = filtered_protected_material_outputs.to_eval_qr_json_lines()\n",
    "filtered_protected_material_file_path = \"filtered_protected_material_output.jsonl\"\n",
    "\n",
    "# Write the output to the file\n",
    "with Path.open(Path(filtered_protected_material_file_path), \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_result = evaluate(\n",
    "    data=filtered_protected_material_file_path,\n",
    "    evaluators={\"protected_material\": protected_material_eval},\n",
    "\n",
    "    azure_ai_project=azure_ai_project,\n",
    "\n",
    "    output_path=\"./myfilteredevalresults.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "\n",
    "\n",
    "async def xpia_callback(\n",
    "    messages: List[Dict], stream: bool = False, session_state: Optional[str] = None, context: Optional[Dict] = None\n",
    ") -> dict:\n",
    "    messages_list = messages[\"messages\"]\n",
    "    # get last message\n",
    "    latest_message = messages_list[-1]\n",
    "    query = latest_message[\"content\"]\n",
    "    context = None\n",
    "    if \"file_content\" in messages[\"template_parameters\"]:\n",
    "        query += messages[\"template_parameters\"][\"file_content\"]\n",
    "\n",
    "\n",
    "    # Get a client handle for the model\n",
    "    deployment = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "\n",
    "    token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "    oai_client = AzureOpenAI(\n",
    "        azure_endpoint=os.environ.get(\"AZURE_ENDPOINT\"),\n",
    "        api_version=os.environ.get(\"AZURE_API_VERSION\"),\n",
    "        azure_ad_token_provider=token_provider,\n",
    "    )\n",
    "    try:\n",
    "        response_from_oai_chat_completions = oai_client.chat.completions.create(\n",
    "            messages=[{\"content\": query, \"role\": \"user\"}], model=deployment, max_tokens=300\n",
    "        )\n",
    "        print(response_from_oai_chat_completions)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} with content length {len(query)}\")\n",
    "        # to continue the conversation, return the messages, else you can fail the adversarial with an exception\n",
    "        message = {\n",
    "            \"content\": \"Something went wrong. Check the exception e for more details.\",\n",
    "            \"role\": \"assistant\",\n",
    "            \"context\": None,\n",
    "        }\n",
    "        messages[\"messages\"].append(message)\n",
    "        return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state}\n",
    "    response_result = response_from_oai_chat_completions.choices[0].message.content\n",
    "    formatted_response = {\n",
    "        \"content\": response_result,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": {},\n",
    "    }\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state, \"context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_attack_simulator = IndirectAttackSimulator(\n",
    "    azure_ai_project=azure_ai_project, credential=DefaultAzureCredential()\n",
    ")\n",
    "\n",
    "unfiltered_indirect_attack_outputs = await indirect_attack_simulator(\n",
    "    target=xpia_callback,\n",
    "    scenario=AdversarialScenario.ADVERSARIAL_INDIRECT_JAILBREAK,\n",
    "    max_simulation_results=10,\n",
    "    max_conversation_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(unfiltered_indirect_attack_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results are truncated for brevity.\n",
    "truncation_limit = 50\n",
    "for output in unfiltered_indirect_attack_outputs:\n",
    "    for turn in output[\"messages\"]:\n",
    "        content = turn[\"content\"]\n",
    "        if isinstance(content, dict):  # user response from callback is dict\n",
    "            print(f\"{turn['role']} : {content['content'][0:truncation_limit]}\")\n",
    "        elif isinstance(content, tuple):  # assistant response from callback is tuple\n",
    "            print(f\"{turn['role']} : {content[0:truncation_limit]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "print(unfiltered_indirect_attack_outputs)\n",
    "print(unfiltered_indirect_attack_outputs.to_eval_qr_json_lines())\n",
    "output = unfiltered_indirect_attack_outputs.to_eval_qr_json_lines()\n",
    "xpia_file_path = \"unfiltered_indirect_attack_outputs.jsonl\"\n",
    "\n",
    "# Write the output to the file\n",
    "with Path.open(Path(xpia_file_path), \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indirect_attack_eval = IndirectAttackEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "file_path = \"indirect_attack_outputs.jsonl\"\n",
    "result = evaluate(\n",
    "    data=xpia_file_path,\n",
    "    evaluators={\n",
    "        \"indirect_attack\": indirect_attack_eval,\n",
    "    },\n",
    "\n",
    "    azure_ai_project=azure_ai_project,\n",
    "\n",
    "    output_path=\"./mynewindirectattackevalresults.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indirect_attack_outputs = await indirect_attack_simulator(\n",
    "    target=xpia_callback,  # now with the Prompt Shield attached to our model deployment\n",
    "    scenario=AdversarialScenario.ADVERSARIAL_INDIRECT_JAILBREAK,\n",
    "    max_simulation_results=10,\n",
    "    max_conversation_turns=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_indirect_attack_outputs)\n",
    "print(filtered_indirect_attack_outputs.to_eval_qr_json_lines())\n",
    "output = filtered_indirect_attack_outputs.to_eval_qr_json_lines()\n",
    "xpia_file_path = \"filtered_indirect_attack_outputs.jsonl\"\n",
    "\n",
    "# Write the output to the file\n",
    "with Path.open(Path(xpia_file_path), \"w\") as file:\n",
    "    file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indirect_attack_result = evaluate(\n",
    "    data=xpia_file_path,\n",
    "    evaluators={\"indirect_attack\": indirect_attack_eval},\n",
    "\n",
    "    azure_ai_project=azure_ai_project,\n",
    "\n",
    "    output_path=\"./myindirectattackevalresults.json\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-azureai-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
